# Obelysk Model Preset: Custom Model Template
# ═══════════════════════════════════════════════════════════
#
# Copy this file and fill in your model's parameters:
#   cp custom.env.template my-model.env
#   # Edit my-model.env with your values
#   ./01_setup_model.sh --config configs/my-model.env
#
# Required fields:
#   MODEL_NAME    — short identifier (used for directory naming)
#   MODEL_HF      — HuggingFace repo (e.g., "org/model-name")
#                   OR set MODEL_ONNX for a local .onnx file
#   MODEL_LAYERS  — number of transformer layers to prove
#
# Optional fields (auto-detected from config.json if omitted):
#   MODEL_QUANT, MODEL_HIDDEN, MODEL_NUM_ATTENTION_HEADS, etc.
#
# ═══════════════════════════════════════════════════════════

# Identifier (no spaces, used for directory naming)
MODEL_NAME="my-custom-model"

# HuggingFace model repo (leave empty if using ONNX)
MODEL_HF="org/model-name"

# OR path to local ONNX file (leave empty if using HF)
# MODEL_ONNX="/path/to/model.onnx"

# Number of transformer layers to prove
MODEL_LAYERS=32

# Quantization strategy: symmetric8, asymmetric8, direct, int4
MODEL_QUANT="symmetric8"

# Expected download size in GB (for progress estimation)
MODEL_SIZE_GB=16

# Expected number of SafeTensor shard files
MODEL_SHARDS=4

# Architecture parameters (auto-detected if omitted)
# MODEL_HIDDEN=4096
# MODEL_INTERMEDIATE=14336
# MODEL_NUM_ATTENTION_HEADS=32
# MODEL_NUM_KEY_VALUE_HEADS=8
# MODEL_ACTIVATION="swiglu"
# MODEL_VOCAB_SIZE=128256
# MODEL_MAX_POSITION=131072

# Human-readable description
DESCRIPTION="Custom model — fill in details"
